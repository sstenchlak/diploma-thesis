\chapter{Implementation}\label{chapters:implementation}

This chapter aims to provide implementation details of the fundamental concepts introduced during the analysis in \autoref{chapters:analysis} and formalized in \autoref{chapters:formal-background}, hence closing the reasoning process. Its purpose is not to replace complete technical documentation, which can be found in a project repository (see the end of this thesis for more information).

\bigskip

The work intends to build a solid foundation for an ecosystem of tools with the core framework for schema modeling. The key elements that shall be followed to achieve this goal are:
\begin{enumerate}
    \item All model data and configuration shall be stored in RDF. - \textit{There is already an ecosystem of tools that can work with RDF. It is easily shareable and linkable.}
    \item The core framework shall work on its own. - \textit{It shall be possible to integrate into other applications. The tool is only a user-friendly interface to execute the framework.}
    \item Generators shall work as plugins for the core framework. - \textit{The idea is that anyone can design generators for their specific purpose.}
    \item The model shall be robust and extensible.
\end{enumerate}

Due to the current use case and state of development, our primary focus is to create a tool where is easy to design schemas and generate the required artifacts. Hence the goals above are not met yet, but some design decisions were made to fulfill them later easily.

\afterpage{%
\begin{figure}\centering
    \begin{tikzpicture}
        \node[alice,human,shirt=violet] (dm) at (0,0) {Data modeler};
        \node[bob,human] (sd) at (0,-2.5) {Schema designer};

        \node[squarednode] (oe) at (6,0) {Ontology\\editor};
        \node[squarednode, database] (od) at (11,0) {Ontology\\database};
        \node[squarednode, database] (od2) at (11,-2.5) {Another\\ontology\\database};

        \node[schema] (ds) at (6,-2.5) {Instance of\\Dataspecer};

        \node[squarednode, dashed] (ds2) at (6,-5) {Another instance\\of Dataspecer};


        \draw[-latex] (dm) -- node[above,align=center]{Uses external tool\\to create an ontology} (oe);
        \draw[-latex] (oe) -- node[above,align=center]{Modifies the\\ontology} (od);
        \draw[-latex] (sd) -- node[above,align=center]{Uses the tool\\to create schemas} (ds);
        \draw[-latex] (ds) --  (od);
        \draw[-latex] (ds) -- node[above,align=center,pos=.6]{Reads\\ontologies} (od2);
        \draw[-latex,dashed] (ds) -- node[left,align=right]{Reuses specifications\\or inherits schemas} (ds2);
    \end{tikzpicture}
    \caption{Context of the tool with other systems. Dataspecer only reads the ontology, which is modeled in other tools. The dashed line shows the intent to make the tools interoperable across the Internet as the tools shall be able to reuse and inherit specifications from each other.}
    \label{fig:context-of-the-tool}
\end{figure}
\def\h{1.3cm}\def\sp{0.5cm}
\begin{figure}\centering
    \begin{tikzpicture}[
        every node/.style={anchor=north west},scale=.85, transform shape
    ]
        \node[mapping,minimum width=1.5cm,minimum height=\h] (react) at (0,0) {React\\libs.};
        \node[pimAssociationend,minimum width=2.5cm,minimum height=\h] (op) at (2,0) {Operation\\executor};
        \node[pimAssociationend,minimum width=3cm,minimum height=\h] (com) at (5,0) {Complex op.\\executor};
        \node[ontology,minimum width=5cm,minimum height=\h] (cim) at (8.5,0) {CIM\\adapter};

        \node[ontology,database,minimum width=2cm,minimum height=\h,anchor=north] (ontology1) at (9.5,{1.2*(\h+\sp)}) {Ontology\\database};
        \node[anchor=center] at (11,{1.2*(\h+\sp)-\h/2}) {...};
        \node[ontology,database,minimum width=2cm,minimum height=\h,anchor=north] (ontologyN) at (12.5,{1.2*(\h+\sp)}) {Ontology\\database};

        \node[squarednode,minimum width=13.5cm,minimum height=\h] (fed) at (0,{-1*(\h+\sp)}) {Federated store};

        \node[schema,minimum width=2cm,minimum height=\h] (ss1) at (0,{-2*(\h+\sp)}) {Schema\\store 1};
        \node[anchor=center] at (2.5,{-2*(\h+\sp)-\h/2}) {...};
        \node[schema,minimum width=2cm,minimum height=\h] (ssn) at (3,{-2*(\h+\sp)}) {Schema\\store N};

        \node[schema,minimum width=2cm,minimum height=\h] (ss21) at (8.5+0,{-2*(\h+\sp)}) {Schema\\store 1};
        \node[anchor=center] at (11,{-2*(\h+\sp)-\h/2}) {...};
        \node[schema,minimum width=2cm,minimum height=\h] (ss2n) at (8.5+3,{-2*(\h+\sp)}) {Schema\\store N};

        \node[squarednode,minimum width=5cm,minimum height=\h] (s1) at (0,{-3*(\h+\sp)}) {Store};
        \node[squarednode,minimum width=5cm,minimum height=\h] (sn) at (8.5,{-3*(\h+\sp)}) {Store};

        \node[schema,database,minimum height=\h,anchor=north] (sd1) at (2.5,{-4*(\h+\sp)}) {Schema\\database 1};
        \node[anchor=center] at (6.75,{-4*(\h+\sp)-\h/2}) {...};
        \node[schema,database,minimum height=\h,anchor=north] (sdn) at (11,{-4*(\h+\sp)}) {Schema\\database N};

        \draw [decorate,decoration = {brace, mirror}] (14,{-2*(\h+\sp)-\h}) --  (14,{-2*(\h+\sp)});

        \node[seda,minimum width=\h,minimum height={\h*3+\sp*2}] (configuration) at (15,{-0*(\h+\sp)}) {\rotatebox{90}{Configuration}};

        \draw[-latex] (s1) -- (sd1);
        \draw[-latex] (sn) -- (sdn);

        \draw[-latex] (ss1) -- ([xshift=-1.5cm]s1.north);
        \draw[-latex] (ssn) -- ([xshift=1.5cm]s1.north);
        \draw[-latex] (ss21) -- ([xshift=-1.5cm]sn.north);
        \draw[-latex] (ss2n) -- ([xshift=1.5cm]sn.north);

        \draw[-latex] ([xshift=-5.75cm]fed.south) -- (ss1);
        \draw[-latex] ([xshift=-2.75cm]fed.south) -- (ssn);
        \draw[-latex] ([xshift=2.75cm]fed.south) -- (ss21);
        \draw[-latex] ([xshift=5.75cm]fed.south) -- (ss2n);

        \draw[-latex] (com) -- (cim);
        \draw[-latex] (com) -- (op);

        \draw[-latex] (react) -- ([xshift={0.75cm-13.5cm/2}]fed.north);

        \draw[-latex] (com) -- ([xshift={3cm/2+5cm-13.5cm/2}]fed.north);
        \draw[-latex] (op) -- ([xshift={2.5cm/2+2cm-13.5cm/2}]fed.north);

        \draw[-latex] ([xshift={8.5cm+2cm/2-11cm}]cim.north) -- (ontology1);
        \draw[-latex] ([xshift={11.5cm+2cm/2-11cm}]cim.north) -- (ontologyN);

        \draw[latex-] ([yshift={(\h*3+\sp*2)/2-\h/2}]configuration.west) -- (cim);
        \draw[latex-] ([yshift={(\h*3+\sp*2)/2-2*(\h+\sp)-\h+\h/2}]configuration.west) -- (14.1,{-2*(\h+\sp)-\h/2});

    \end{tikzpicture}
    \caption{Schematic structure of the core framework and the tool. Below, there are various schema databases. Currently, there is only Dataspecer's backend, but others are planned, such as Solid Pods or Triplestores. Each database is read by store, which formally consists of schema stores containing exactly one PIM or PSM schema with all entities. All stores are merged for easier manipulation, such as executing operations. We have also implemented React library to integrate the store into React ecosystem. Based on the data specification, the configuration selects the stores that should be loaded.} \label{fig:schematic}
\end{figure}
\clearpage
}

\bigskip

\autoref{fig:context-of-the-tool} depicts the most zoomed-out view of the toolâ€™s architecture, where the tool is shown in the context of other applications. We have noted several times that we focus only on schema modeling, whereas conceptual modeling is done elsewhere. We also plan that multiple instances of the tool may exist, each using its own database, yet still be able to provide all the functionality, such as schema reference and evolution.

\paragraph{Container structure} Currently, the tool consists of a \textbf{backend}, \textbf{manager}, \textbf{editor}, and a \textbf{CLI service}.

The backend is a Node.js server that provides functionality for some generators, such as a documentation generator that requires a Python module to build the resulting HTML file. The backend also serves as the storage for modeled schemas. (see the bottommost layer of \autoref{fig:schematic}) We also plan to use other types of storage, such as personal Solid Pods, triplestores in general, or read-only documents stored on the internet.

The manager is a React application that can manage schemas stored in the backend and execute generators. It then opens an editor under a given configuration which is another React application purely designed for schema editing. A CLI service is a command line tool used for semi-automated testing of generated schemas and transformations.

\paragraph{Framework structure} The operation execution with schema generation is bundled into the tools, as it is just a TypeScript library. Hence the tools do all the work, and the backend serves as a simple database. This is a sufficient solution for now (and necessary for most backends, such as triplestore or Solid Pods), but the structure of operations and the whole framework allows for executing the operations remotely on the server as well. This may be especially useful for large schemas during the evolution process when the difficult part can be performed safely by the server and the client only updates the local copy.

\section{Model representation} % po sem kontroly ok

As model data are represented by entities that shall be serialized in RDF, we introduce a \textbf{schema store} as an abstraction layer. The schema store can read and write \textbf{resources}, where the resource is a document/object that contains arbitrary data. In the context of PIM and PSM, the entity is a resource. Resources are identified by their IRI, which is an IRI of the corresponding RDF resource.

Entities can be read from the schema store, but writing is limited to \textbf{operations}. Operations that were executed are saved in the schema store to provide a history of the model at any given point in time. Schema store must contain exactly one \textbf{schema resource}. A schema resource is a resource that identifies all other entities in the schema store, formally creating a set of resources.

Schema stores are managed in \textbf{stores}. The store is an interface for reading resources by their IRI and executing operations on a given schema resource. The store is asynchronous and represents a database of resources. For example, a store may be an interface on the SPARQL endpoint, a file system, a read-only dump on the internet, or just data in local memory.

The current implementation of the tool uses stores that are synchronized with the server through a simple GET-POST API.\footnote{This de facto implicitly supports Solid Pods as a type of store.} Stores on the server are saved into individual files in the filesystem. Each store contains only one schema store for better granularity, as the file must be read and written atomically.

\medskip

The store also shall generate new IRIs that can be later assigned to entities. IRIs needs to be generated in advance to be part of the operation, so we can later identify which entities were created. Depending on the store, the IRIs may have different structures.

The current implementation only supports a simple reading by IRI. This will be changed in the future for more advanced query operations, such as reverse lookup for the entity.

\medskip

Stores' interface allows creating of \textbf{federated stores}, hence allowing to have only a single interface for reading and writing any entity. This simplifies the application's design, as we may have a complex system of shared and reused data specifications, some of them possibly read-only, from different sources.

\medskip

In previous chapters, we have considered PIM as both the layer in general (PIM layer) and the set of PIM entities we have formally defined (PIM schema). The latter one, the PIM schema, is represented by one specific schema store. Similarly, the PSM schema (possibly having multiple roots) is also represented by one schema store. To simplify the design, the schema resource that is necessary for every schema store will also represent the PIM or PSM schema. To make the previous sentence clear, suppose PSM schema $S$. The schema contains entities such as classes, ORs, etc. Those entities are represented by resources. But the schema itself, which contains, for example, a set of roots, also needs to be represented by a resource. And the resource will be the schema resource.

This all means that if a user creates a data specification with two schemas, three schema stores are created: one for the PIM schema and two for the PSM schemas. Hence three stores represented by three files are created as well.

\medskip

As we have noted, operations can be executed remotely. The current implementation of the store contains logic for local operation execution, hence all operations are evaluated on the client and only the final result is sent to the server. It is, however, possible to send the operations to the server and fetch the changes. This approach is useful for better synchronization of different clients as two clients may execute operations at the same time, possibly causing a collision.

Unfortunately, we can not go any further by executing complex operations on the server, as different schemas may be stored in different stores. A possible solution would be to introduce a proxy server, that would perform these complex operations on the given stores remotely.

\paragraph{Data specification}

Although data specifications are also identified by IRIs, they are not resources in the same sense as PIM or PSM entities. We do not require write-through-operation access and are also read in different situations. Current implementation stores them in SQL database for fast access (which is against the first rule that everything shall be stored in RDF).

A data specification contains, namely, (i) a set of reused data specifications' IRIs, (ii) a PIM schema's IRI, (iii) a list of PSM schemas' IRIs, and (iv) a set of stores' IRIs where the appropriate schemas can be found and (v) an artifact configuration.

\section{Layers for simplifying the model}

Reading the model may be too complex, as the entities may not exist, reading them requires asynchronous access, and to obtain the value of all annotations, we usually need to go to the PIM layer. Letting individual generators access the model is, of course, necessary, but for most generators, this would mean implementing many helper functions for easier access. To reduce the burden on generators, we introduce conceptual and structural models whose purpose is to provide a more user-friendly interface for reading the model.

\paragraph{Conceptual model} Conceptual model is fairly simple as it only simplifies access to PIM, which is simple by itself. Its structure is similar to PIM, but attributes and associations are referenced directly from the class as properties. The whole model is constructed in advance, hence we can check whether is correct and do not need to do it during the querying. But mainly we can access everything synchronously.

\paragraph{Structural model} Structural model employs a different approach to schema structure than PSM. As PSM is highly inspired by schemas, it also has a more schema-like structure. For example, include is valid class property, but from an object-oriented view, it has more semantic meaning. The structural model we use tends to be more object-oriented.

Classes have properties as well, but the properties represent only attributes and associations. Include is translated to class inheritance, as it works almost precisely the same as inheriting properties from a parent class. The only difference is that the position of the include can not be preserved. This, however, for most generators, is not an issue.

To simplify the work with disjunction, we exploit the fact that OR on one element is the same as the element without OR. Hence, all associations have an array of referred classes as OR between them. This won't introduce new objects that need to be specially handled and allows domain-specific generators to ignore the concept at all if it is not required.

It may seem, that this goes against our design, as we, after all, use an interface for object-oriented access. Our intent is, however, to have a robust model that can handle a wide range of use-cases and rather create a layer for easier access.

\paragraph{Transformations} Conceptual and structural models provide various transformations (do not confuse with data transformations from \autoref{req:transformations}) that modifies the model or obtain additional data for given generator.

\begin{itemize}
    \item It is possible to flatten the structural model by copying properties from parent to child classes. This transformation may simplify the work for developers of generators as they do not need to handle inheritance anymore (hence the include). Of course, this would cause the artifact to grow as the entities are not reused but may be useful for an early stage of development as simplification.
    \item As some information lies in PIM, such as naming, description, default cardinality, or datatype, there is a transformation that fetches this information to the structural model.
    \item Associations marked as dematerialized (dematerialization is an annotation on the association that specifies, that all properties from the associated class shall be put into a parent class) may be "unpacked" to the parent class instead of the association itself.
\end{itemize}

\paragraph{Format-aware structural models} As there is usually a whole ecosystem of generators that work with a given technology, such as XML, it is important to let the designers extend or even transform the model on their own, making it format-aware. We already use this technique for XML to add namespace information to the entities. In general, the transformation may change the interface of the structural model to suit the needs of the generator better. The transformation may, for example, add a new type of class property that was extracted from PSM.

\section{Artifacts generation}

To properly generate artifacts that can reference each other, which is a crucial feature for the documentation, and to keep them highly configurable, we have employed the following interface. First, its configuration must be provided. The configuration consists of:

\begin{enumerate}
    \item IRI of the given artifact.
    \item IRI of the generator to be used to create given artifact.
    \item Output path, as the generated artifact has to be stored somewhere. (a directory can be provided for generators, that create more than one file)
    \item Public URL, as we expect, that the artifacts will be uploaded on the Internet. In most cases, the public URL shall be the same as the output path, which creates relative URLs between the artifacts.
    \item Generators that reference other artifacts require their IRIs.
    \item For schema artifacts, the IRI of the PSM schema is required.
\end{enumerate}

To generate this array of configurations, ArtifactConfigurator is used. The configurator itself is configured from data specification. The typical options are whether to generate all schemas, how the file structure should look like or the configuration for individual generators, such as whether CSV schema shall use multiple tables for the given schema.

\section{CIM adapter}

Currently, we support only one CIM adapter (with others planned) for Semantic Government Vocabulary (SGOV) \cite{kvremen2019improving}, as we have no use cases that would require others. In general, which adapters (multiple can be used) are used for a given schema are configured in data specification. Although this may not be necessary, and all adapters can be used all the time, we still want to limit this as the user may accidentally select a concept from a wrong ontology, and all the ontologies would have to be queried.

To follow the definition of CIM, the CIM adapter returns resources as a read-only temporary store containing PIM entities. Those PIM entities are then inserted into the actual PIM through the operations. For example, when a user searches ontology for a root class, the adapter returns a list of PIM classes from the search query. The user then picks one PIM class which is passed to the complex operation that creates atomic operations on both PIM and PSM levels and properly adds the class to the schema.

Besides the search operation, the CIM adapter provides functions for obtaining the class surroundings, full hierarchy or CIM adapter-specific properties. The last functionality provides data that are not stored in PIM but may be handy to show additional information about resources. For example a URL to the resource on the Internet (as not always the IRI gives access to the resource with human-friendly results).

Our SGOV adapter also returns tags for the resources. These tags are then shown in the UI to help the user better understand which resources to choose, as sometimes, there can be multiple resources with the same name. Nevertheless, we currently do not store the tags in the PIM to be accessible by generators. In general, this\footnote{We mean any additional properties that have no impact on the data conforming to generated schemas.} would need to be analyzed concerning the evolution and local modifications, and what would it mean if they change.

\medskip

All resources that are returned from the CIM adapter are consistent with CIM, not identical. This specifically means that the returned resource, for example, may not contain all extended classes (in the case of searching for the resource, this is not necessary).