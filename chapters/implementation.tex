\chapter{Implementation}\label{chapters:implementation}

This chapter aims to provide implementation details of the fundamental concepts introduced during the analysis in \autoref{chapters:analysis} and formalized in \autoref{chapters:formal-background}, hence closing the reasoning process. Its purpose is not to replace complete technical documentation, which can be found in a project repository (see the end of this thesis for more information).

\bigskip

The intent of the work is to build a solid foundation for an ecosystem of tools with the core framework for schema modeling. The key elements that shall be followed to achieve this goal are:
\begin{enumerate}
    \item All model data and configuration shall be stored in RDF - \textit{There is already an ecosystem of tools that can work with RDF. It is easily shareable and linkable.}
    \item The core framework shall work on its own - \textit{It shall be possible to integrate into other applications. The tool is only a user-friendly interface to execute the framework.}
    \item Generators shall work as plugins for the core framework - \textit{The idea is that anyone can design generators for their specific purpose.}
    \item The model shall be robust and extensible
\end{enumerate}

Due to the current use case and state of development, our primary focus is to create a tool where is easy to design schemas and generate the required artifacts. Hence the goals above are not met yet, but some design decisions were made to fulfill them later easily.

\afterpage{%
\begin{figure}\centering
    \begin{tikzpicture}
        \node[alice,human,shirt=violet] (dm) at (0,0) {Data modeler};
        \node[bob,human] (sd) at (0,-2.5) {Schema designer};

        \node[squarednode] (oe) at (6,0) {Ontology\\editor};
        \node[squarednode, database] (od) at (11,0) {Ontology\\database};
        \node[squarednode, database] (od2) at (11,-2.5) {Another\\ontology\\database};

        \node[schema] (ds) at (6,-2.5) {Instance of\\Dataspecer};

        \node[squarednode, dashed] (ds2) at (6,-5) {Another instance\\of Dataspecer};


        \draw[-latex] (dm) -- node[above,align=center]{Uses external tool\\to create an ontology} (oe);
        \draw[-latex] (oe) -- node[above,align=center]{Modifies the\\ontology} (od);
        \draw[-latex] (sd) -- node[above,align=center]{Uses the tool\\to create schemas} (ds);
        \draw[-latex] (ds) --  (od);
        \draw[-latex] (ds) -- node[above,align=center,pos=.6]{Reads\\ontologies} (od2);
        \draw[-latex,dashed] (ds) -- node[left,align=right]{Reuses specifications\\or inherits schemas} (ds2);
    \end{tikzpicture}
    \caption{Context of the tool with other systems. Dataspecer only reads the ontology, which must be modelled in other tools. Dashed line shows the intent to make the tools interoperable across the Internet.}
\end{figure}
\def\h{1.3cm}\def\sp{0.5cm}
\begin{figure}\centering
    \begin{tikzpicture}[
        every node/.style={anchor=north west},scale=.85, transform shape
    ]
        \node[mapping,minimum width=1.5cm,minimum height=\h] (react) at (0,0) {React\\libs.};
        \node[pimAssociationend,minimum width=2.5cm,minimum height=\h] (op) at (2,0) {Operation\\executor};
        \node[pimAssociationend,minimum width=3cm,minimum height=\h] (com) at (5,0) {Complex op.\\executor};
        \node[ontology,minimum width=5cm,minimum height=\h] (cim) at (8.5,0) {CIM\\adapter};

        \node[ontology,database,minimum width=2cm,minimum height=\h,anchor=north] (ontology1) at (9.5,{1.2*(\h+\sp)}) {Ontology\\database};
        \node[anchor=center] at (11,{1.2*(\h+\sp)-\h/2}) {...};
        \node[ontology,database,minimum width=2cm,minimum height=\h,anchor=north] (ontologyN) at (12.5,{1.2*(\h+\sp)}) {Ontology\\database};

        \node[squarednode,minimum width=13.5cm,minimum height=\h] (fed) at (0,{-1*(\h+\sp)}) {Federated store};

        \node[schema,minimum width=2cm,minimum height=\h] (ss1) at (0,{-2*(\h+\sp)}) {Schema\\store 1};
        \node[anchor=center] at (2.5,{-2*(\h+\sp)-\h/2}) {...};
        \node[schema,minimum width=2cm,minimum height=\h] (ssn) at (3,{-2*(\h+\sp)}) {Schema\\store N};

        \node[schema,minimum width=2cm,minimum height=\h] (ss21) at (8.5+0,{-2*(\h+\sp)}) {Schema\\store 1};
        \node[anchor=center] at (11,{-2*(\h+\sp)-\h/2}) {...};
        \node[schema,minimum width=2cm,minimum height=\h] (ss2n) at (8.5+3,{-2*(\h+\sp)}) {Schema\\store N};

        \node[squarednode,minimum width=5cm,minimum height=\h] (s1) at (0,{-3*(\h+\sp)}) {Store};
        \node[squarednode,minimum width=5cm,minimum height=\h] (sn) at (8.5,{-3*(\h+\sp)}) {Store};

        \node[schema,database,minimum height=\h,anchor=north] (sd1) at (2.5,{-4*(\h+\sp)}) {Schema\\database 1};
        \node[anchor=center] at (6.75,{-4*(\h+\sp)-\h/2}) {...};
        \node[schema,database,minimum height=\h,anchor=north] (sdn) at (11,{-4*(\h+\sp)}) {Schema\\database N};

        \draw [decorate,decoration = {brace, mirror}] (14,{-2*(\h+\sp)-\h}) --  (14,{-2*(\h+\sp)});

        \node[seda,minimum width=\h,minimum height={\h*3+\sp*2}] (configuration) at (15,{-0*(\h+\sp)}) {\rotatebox{90}{Configuration}};

        \draw[-latex] (s1) -- (sd1);
        \draw[-latex] (sn) -- (sdn);

        \draw[-latex] (ss1) -- ([xshift=-1.5cm]s1.north);
        \draw[-latex] (ssn) -- ([xshift=1.5cm]s1.north);
        \draw[-latex] (ss21) -- ([xshift=-1.5cm]sn.north);
        \draw[-latex] (ss2n) -- ([xshift=1.5cm]sn.north);

        \draw[-latex] ([xshift=-5.75cm]fed.south) -- (ss1);
        \draw[-latex] ([xshift=-2.75cm]fed.south) -- (ssn);
        \draw[-latex] ([xshift=2.75cm]fed.south) -- (ss21);
        \draw[-latex] ([xshift=5.75cm]fed.south) -- (ss2n);

        \draw[-latex] (com) -- (cim);
        \draw[-latex] (com) -- (op);

        \draw[-latex] (react) -- ([xshift={0.75cm-13.5cm/2}]fed.north);

        \draw[-latex] (com) -- ([xshift={3cm/2+5cm-13.5cm/2}]fed.north);
        \draw[-latex] (op) -- ([xshift={2.5cm/2+2cm-13.5cm/2}]fed.north);

        \draw[-latex] ([xshift={8.5cm+2cm/2-11cm}]cim.north) -- (ontology1);
        \draw[-latex] ([xshift={11.5cm+2cm/2-11cm}]cim.north) -- (ontologyN);

        \draw[latex-] ([yshift={(\h*3+\sp*2)/2-\h/2}]configuration.west) -- (cim);
        \draw[latex-] ([yshift={(\h*3+\sp*2)/2-2*(\h+\sp)-\h+\h/2}]configuration.west) -- (14.1,{-2*(\h+\sp)-\h/2});

    \end{tikzpicture}
    \caption{Schematic structure of the core framework and the tool. Below, there are various schema databases. Currently, there is only Dataspecer's backend, but others are planned, such as Solid Pods or Triplestores. Each database is read by store, which formally consists of schema stores, containing exactly one PIM or PSM schema with all entities. All stores are merged for easier manipulation, such as executing operations. We have also implemented React library to integrate the store into React ecosystem. Configuration, based on the data specification, select the stores that should be loaded.  } % Schema C shows a proposition for schema extending and is described later in the thesis.
\end{figure}
\clearpage
}

\section{Model representation}

\subsection{Store}

As model data are represented by entities that shall be serialized in RDF, we introduce a \textbf{schema store} as an abstraction layer. The schema store can read and write \textbf{resources}, where the resource is a document/object that contains arbitrary data. In the context of PIM and PSM, the entity is a resource. Resources are identified by their IRI, which is an IRI of the corresponding RDF resource.

Entities can be read from the schema store, but writing is limited to \textbf{operations}. Operations that were executed are saved in the schema store to provide a history of the model at any given point in time. Schema store must contain exactly one \textbf{schema resource}. A schema resource is a resource that identifies all other entities in the schema store, formally creating a set of resources.

Schema stores are managed in \textbf{stores}. The store is an interface for reading resources by their IRI and executing operations on a given schema resource. The store is asynchronous and represents a database of resources. For example, a store may be an interface on the SPARQL endpoint, a file system, a read-only dump on the internet, or just data in local memory.

The current implementation of the tool uses stores that are synchronized with the server through a simple GET-POST API.\footnote{This de facto implicitly supports Solid Pods as a type of store.} Stores on the server are saved into individual files in the filesystem. Each store contains only one schema store for better granularity, as the file must be read and written atomically.

\medskip

The store also shall generate new IRIs that can be later assigned to entities. IRIs needs to be generated in advance to be part of the operation, so we can later identify which entities were created. Depending on the store, the IRIs may have different structures.

The current implementation only supports a simple reading by IRI. This will be changed in the future for more advanced query operations, such as reverse lookup for the entity.

\medskip

Stores' interface allows creating of \textbf{federated stores}, hence allowing to have only a single interface for reading and writing any entity. This simplifies the application's design, as we may have a complex system of shared and reused data specifications from different sources.

\medskip

In previous chapters, we have considered PIM as both the layer in general (PIM layer) and the set of PIM entities we have formally defined (PIM schema). The latter one, the PIM schema, is represented by one specific schema store. Similarly, the PSM schema (possibly having multiple roots) is also represented by one schema store. To simplify the design, the schema resource that is necessary for every schema store will also represent the PIM or PSM schema. To make the previous sentence clear, suppose PSM schema $S$. The schema contains entities such as classes, ORs, etc. Those entities are represented by resources. But the schema itself, which contains, for example, a set of roots, also needs to be represented by a resource. And the resource will be the schema resource.

This means that if a user creates a data specification with two schemas, three schema stores are created: one for the PIM schema and two for the PSM schemas. Hence three stores represented by three files are created as well.

\subsection{Data specification}

The resource that represents data specification contains, namely, (i) a set of reused data specifications' IRIs, (ii) a set of PIM schemas' IRIs, (iii) a list of PSM schemas' IRIs, (iv) a set of stores' IRIs where the appropriate schemas can be found and (v) an artifact configuration.

\section{Layers for simplifying the model}

Reading the model may be too complex, as the entities may not exist, reading them requires asynchronous access, and to obtain the value of all annotations, we usually need to go to the PIM layer. Letting individual generators access the model is, of course, necessary, but for most generators, this would mean implementing many helper functions for easier access. To reduce the burden on generators, we introduce conceptual and structural models whose purpose is to provide a more user-friendly interface for reading the model.

\paragraph{Conceptual model} Conceptual model is fairly simple as it only simplifies access to PIM, which is simple by itself. Its structure is similar to PIM, but attributes and associations are referenced directly from the class as properties. The whole model is constructed in advance, hence we can check whether is correct, but mainly we can access everything synchronously.

\paragraph{Structural model} Structural model employs a different approach to schema structure than PSM. As PSM is highly inspired by schemas, it also has a more schema-like structure. For example, include is valid class property, but from an object-oriented view, it has more semantic meaning. The structural model we use tends to be more object-oriented.

Classes have properties as well, but the properties represent only attributes and associations. Include is translated to class inheritance, as it works almost precisely the same as inheriting properties from a parent class. The only difference is that the position of the include can not be preserved. This, however, for most generators, is not an issue.

To simplify the work with disjunction, we exploit the fact that OR on one element is the same as the element without OR. Hence, all associations have an array of referred classes. This won't introduce new objects that need to be specially handled and allows domain-specific generators to ignore the concept at all if it is not required.

\paragraph{Transformations} Both conceptual and structural models provide various transformations (do not confuse with data transformations from \autoref{req:transformations}) that simplify the model or obtain additional data.

\begin{itemize}
    \item It is possible to flatten the structural model by copying properties from parent to child classes. This transformation may simplify the work for developers of generators as they do not need to handle inheritance anymore. Of course, this would cause the artifact to grow as the entities are not reused but may be useful for an early stage of development as simplification.
    \item As some information lies in PIM, such as naming, description, default cardinality, or datatype, there is a transformation that fetches this information to the structural model.
    \item Associations marked as dematerialized may be "unpacked" to the parent class instead of the association itself.
\end{itemize}

\paragraph{Format-aware structural models} As there is usually a whole ecosystem of generators that work with a given technology, such as XML, it is important to let the designers extend or even transform the model on their own, making it format-aware. We already use this technique for XML to add namespace information to the entities. In general, the transformation may change the interface of the structural model to suit the needs of the generator better.
